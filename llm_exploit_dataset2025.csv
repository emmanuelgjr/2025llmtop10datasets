ID,Exploit Name,Description,Category,Impact,Exploit Examples,Mitigation Strategies,Affected Models,Source,Severity Level,Risk Score
1,Backend Overload Attack,Causes service disruption or exposes confidential model parameters.,Session Management,"Enables adversaries to manipulate responses, compromising integrity.",Using adversarial inputs to exploit weak error handling mechanisms.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,6.2
2,Internal State Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Session Management,"Enables adversaries to manipulate responses, compromising integrity.",Using crafted tokens to alter LLM responses significantly.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,5.2
3,Model Parameter Manipulation,Causes service disruption or exposes confidential model parameters.,Adversarial Attack,Causes service disruption or exposes confidential model parameters.,Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,7
4,LLM Model Rollback Attack,"Can lead to unauthorized access, data leakage, or system misbehavior.",Access Control,"Enables adversaries to manipulate responses, compromising integrity.",Using adversarial inputs to exploit weak error handling mechanisms.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Critical,8.5
5,Covert Prompt Injection,"Results in unintentional outputs, breaching privacy or security policies.",Session Management,Causes service disruption or exposes confidential model parameters.,Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,High,7.1
6,Covert Prompt Injection,"Enables adversaries to manipulate responses, compromising integrity.",Output Manipulation,Causes service disruption or exposes confidential model parameters.,Injecting backdoor prompts during inference to control outputs.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,7.1
7,LLM Integration Bypass,"Can lead to unauthorized access, data leakage, or system misbehavior.",Access Control,"Results in unintentional outputs, breaching privacy or security policies.",Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,8.3
8,Resource Depletion Exploit,Allows attackers to extract sensitive data or alter model behavior.,Model Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Injecting backdoor prompts during inference to control outputs.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Critical,7.3
9,Training Data Inference,"Results in unintentional outputs, breaching privacy or security policies.",Access Control,"Results in unintentional outputs, breaching privacy or security policies.",Injecting backdoor prompts during inference to control outputs.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,8.4
10,Recursive Prompt Attack,Causes service disruption or exposes confidential model parameters.,API Misuse,Allows attackers to extract sensitive data or alter model behavior.,Using adversarial inputs to exploit weak error handling mechanisms.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,7
11,Training Data Replay Attack,"Can lead to unauthorized access, data leakage, or system misbehavior.",Resource Exhaustion,"Can lead to unauthorized access, data leakage, or system misbehavior.",Submitting repeated requests to extract sensitive data from the model.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Critical,9.3
12,Role-Based Model Hijacking,Allows attackers to extract sensitive data or alter model behavior.,Access Control,"Can lead to unauthorized access, data leakage, or system misbehavior.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Critical,8.2
13,Role-Based Model Hijacking,Allows attackers to extract sensitive data or alter model behavior.,Adversarial Attack,Allows attackers to extract sensitive data or alter model behavior.,Injecting backdoor prompts during inference to control outputs.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,High,7.1
14,Model Drift Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Model Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Using crafted tokens to alter LLM responses significantly.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Medium,6.4
15,Output Spoofing,"Enables adversaries to manipulate responses, compromising integrity.",Input Manipulation,Causes service disruption or exposes confidential model parameters.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,High,9.3
16,Weak Model Control Exploit,"Enables adversaries to manipulate responses, compromising integrity.",API Misuse,"Results in unintentional outputs, breaching privacy or security policies.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,High,8.3
17,Exposed Model Parameters,"Results in unintentional outputs, breaching privacy or security policies.",Input Manipulation,Causes service disruption or exposes confidential model parameters.,Using adversarial inputs to exploit weak error handling mechanisms.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,High,8.6
18,Session Hijacking via Token Reuse,"Enables adversaries to manipulate responses, compromising integrity.",Adversarial Attack,Causes service disruption or exposes confidential model parameters.,Submitting repeated requests to extract sensitive data from the model.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,6.5
19,Model Response Chaining,Allows attackers to extract sensitive data or alter model behavior.,Session Management,"Can lead to unauthorized access, data leakage, or system misbehavior.",Injecting backdoor prompts during inference to control outputs.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,5.6
20,Model Parameter Inference,Causes service disruption or exposes confidential model parameters.,Access Control,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using crafted tokens to alter LLM responses significantly.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,9.5
21,Exploit via Unauthenticated Endpoints,"Results in unintentional outputs, breaching privacy or security policies.",Session Management,"Can lead to unauthorized access, data leakage, or system misbehavior.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,4.2
22,LLM Output Tampering,Allows attackers to extract sensitive data or alter model behavior.,Adversarial Attack,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using crafted tokens to alter LLM responses significantly.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,4.9
23,AI-Driven Malicious Code Execution,"Results in unintentional outputs, breaching privacy or security policies.",Model Manipulation,Allows attackers to extract sensitive data or alter model behavior.,Submitting repeated requests to extract sensitive data from the model.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,5.1
24,Inference Time Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Resource Exhaustion,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Low,5.1
25,Output Alignment Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Resource Exhaustion,Allows attackers to extract sensitive data or alter model behavior.,Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,7.5
26,LLM Output Tampering,Causes service disruption or exposes confidential model parameters.,Configuration Error,"Can lead to unauthorized access, data leakage, or system misbehavior.",Injecting backdoor prompts during inference to control outputs.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,6.4
27,Output Spoofing,"Enables adversaries to manipulate responses, compromising integrity.",Input Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,High,4.4
28,Backend Overload Attack,"Results in unintentional outputs, breaching privacy or security policies.",Model Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using adversarial inputs to exploit weak error handling mechanisms.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,9.6
29,Unrestricted Prompt Execution,Allows attackers to extract sensitive data or alter model behavior.,Access Control,Allows attackers to extract sensitive data or alter model behavior.,Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Critical,8.4
30,Data Poisoning Attack,Allows attackers to extract sensitive data or alter model behavior.,Model Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Critical,6.7
31,Output Redirection Attack,"Results in unintentional outputs, breaching privacy or security policies.",Session Management,"Can lead to unauthorized access, data leakage, or system misbehavior.",Submitting repeated requests to extract sensitive data from the model.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,8.7
32,Role Spoofing Exploit,Causes service disruption or exposes confidential model parameters.,Input Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,High,8.6
33,LLM Routing Exploit,"Can lead to unauthorized access, data leakage, or system misbehavior.",Adversarial Attack,Allows attackers to extract sensitive data or alter model behavior.,Using adversarial inputs to exploit weak error handling mechanisms.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Critical,6.5
34,Batch Request Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Session Management,Allows attackers to extract sensitive data or alter model behavior.,Submitting repeated requests to extract sensitive data from the model.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,6.3
35,Training Data Inference,"Can lead to unauthorized access, data leakage, or system misbehavior.",Input Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Submitting repeated requests to extract sensitive data from the model.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Critical,4.1
36,Backend Overload Attack,Causes service disruption or exposes confidential model parameters.,Model Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Low,9.5
37,Model Parameter Enumeration,Allows attackers to extract sensitive data or alter model behavior.,Adversarial Attack,Allows attackers to extract sensitive data or alter model behavior.,Using adversarial inputs to exploit weak error handling mechanisms.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,7.7
38,LLM Routing Exploit,Causes service disruption or exposes confidential model parameters.,Adversarial Attack,"Can lead to unauthorized access, data leakage, or system misbehavior.",Submitting repeated requests to extract sensitive data from the model.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Critical,7.2
39,Deepfake Model Generation,Allows attackers to extract sensitive data or alter model behavior.,API Misuse,"Results in unintentional outputs, breaching privacy or security policies.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,High,6.7
40,Session Replay Vulnerability,Allows attackers to extract sensitive data or alter model behavior.,API Misuse,Causes service disruption or exposes confidential model parameters.,Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,7.6
41,Resource Depletion Exploit,Causes service disruption or exposes confidential model parameters.,Output Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Hijacking sessions by reusing old tokens in LLM-based systems.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Medium,4.9
42,Output Spoofing,Causes service disruption or exposes confidential model parameters.,Resource Exhaustion,"Can lead to unauthorized access, data leakage, or system misbehavior.",Injecting backdoor prompts during inference to control outputs.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,5.1
43,Unauthorized Access to Debug Endpoints,"Results in unintentional outputs, breaching privacy or security policies.",Resource Exhaustion,Causes service disruption or exposes confidential model parameters.,Submitting repeated requests to extract sensitive data from the model.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,6.6
44,Session Management Exploit,"Enables adversaries to manipulate responses, compromising integrity.",Access Control,"Enables adversaries to manipulate responses, compromising integrity.",Injecting backdoor prompts during inference to control outputs.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Low,8.7
45,Model Drift Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Output Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Using adversarial inputs to exploit weak error handling mechanisms.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,High,8.8
46,Model Drift Manipulation,Allows attackers to extract sensitive data or alter model behavior.,Output Manipulation,Allows attackers to extract sensitive data or alter model behavior.,Injecting backdoor prompts during inference to control outputs.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,5.7
47,Output Filter Bypass,Causes service disruption or exposes confidential model parameters.,API Misuse,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Critical,4.3
48,Covert Prompt Injection,"Enables adversaries to manipulate responses, compromising integrity.",Data Leakage,Allows attackers to extract sensitive data or alter model behavior.,Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Low,9.9
49,Predictable Input Crafting,Causes service disruption or exposes confidential model parameters.,Model Manipulation,Causes service disruption or exposes confidential model parameters.,Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,8.9
50,Response Timing Exploitation,Allows attackers to extract sensitive data or alter model behavior.,Access Control,Allows attackers to extract sensitive data or alter model behavior.,Injecting backdoor prompts during inference to control outputs.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,High,4.9
51,Internal State Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Configuration Error,"Results in unintentional outputs, breaching privacy or security policies.",Injecting backdoor prompts during inference to control outputs.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Critical,4.6
52,Training Phase Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Resource Exhaustion,Causes service disruption or exposes confidential model parameters.,Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,4.2
53,Predictive Behavior Shaping,"Enables adversaries to manipulate responses, compromising integrity.",Resource Exhaustion,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,5.5
54,Weak Model Control Exploit,"Can lead to unauthorized access, data leakage, or system misbehavior.",Input Manipulation,Allows attackers to extract sensitive data or alter model behavior.,Using adversarial inputs to exploit weak error handling mechanisms.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Medium,6.7
55,Contextual Injection Attack,"Results in unintentional outputs, breaching privacy or security policies.",Output Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Using adversarial inputs to exploit weak error handling mechanisms.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,High,7.1
56,Misleading Prompt Structure,"Results in unintentional outputs, breaching privacy or security policies.",Adversarial Attack,"Results in unintentional outputs, breaching privacy or security policies.",Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Low,8.1
57,LLM Output Tampering,"Results in unintentional outputs, breaching privacy or security policies.",Session Management,Allows attackers to extract sensitive data or alter model behavior.,Using crafted tokens to alter LLM responses significantly.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,9
58,Batch Request Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Configuration Error,Causes service disruption or exposes confidential model parameters.,Injecting backdoor prompts during inference to control outputs.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,7.5
59,Exploitation of API Misconfigurations,Causes service disruption or exposes confidential model parameters.,Access Control,Causes service disruption or exposes confidential model parameters.,Submitting repeated requests to extract sensitive data from the model.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,9.1
60,Internal State Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Input Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Injecting backdoor prompts during inference to control outputs.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Critical,7.3
61,Cache Poisoning of Model Responses,"Can lead to unauthorized access, data leakage, or system misbehavior.",Access Control,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,5.4
62,Output Alignment Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",API Misuse,Allows attackers to extract sensitive data or alter model behavior.,Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,4.2
63,Cross-Model Input Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Access Control,"Enables adversaries to manipulate responses, compromising integrity.",Submitting repeated requests to extract sensitive data from the model.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,High,4.4
64,Model Parameter Inference,"Can lead to unauthorized access, data leakage, or system misbehavior.",Model Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,6.5
65,LLM Function Call Injection,"Can lead to unauthorized access, data leakage, or system misbehavior.",Adversarial Attack,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,9.6
66,Model Response Chaining,"Results in unintentional outputs, breaching privacy or security policies.",Input Manipulation,Causes service disruption or exposes confidential model parameters.,Using adversarial inputs to exploit weak error handling mechanisms.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Low,8.7
67,Session Hijacking via Token Reuse,Allows attackers to extract sensitive data or alter model behavior.,Output Manipulation,"Results in unintentional outputs, breaching privacy or security policies.",Using crafted tokens to alter LLM responses significantly.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Critical,9.2
68,LLM Output Tampering,"Results in unintentional outputs, breaching privacy or security policies.",Access Control,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,5
69,Session Management Exploit,Causes service disruption or exposes confidential model parameters.,Model Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Using adversarial inputs to exploit weak error handling mechanisms.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Low,7
70,Weak Model Control Exploit,Causes service disruption or exposes confidential model parameters.,Session Management,"Enables adversaries to manipulate responses, compromising integrity.",Injecting backdoor prompts during inference to control outputs.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,6.1
71,Session Hijacking via Token Reuse,"Results in unintentional outputs, breaching privacy or security policies.",API Misuse,Causes service disruption or exposes confidential model parameters.,Using adversarial inputs to exploit weak error handling mechanisms.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Low,9.6
72,Predictive Model Attack,Causes service disruption or exposes confidential model parameters.,Model Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Low,9.7
73,Server-Side Resource Exploit,Allows attackers to extract sensitive data or alter model behavior.,Session Management,"Can lead to unauthorized access, data leakage, or system misbehavior.",Injecting backdoor prompts during inference to control outputs.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,High,7.5
74,Contextual Injection Attack,Allows attackers to extract sensitive data or alter model behavior.,Model Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Submitting repeated requests to extract sensitive data from the model.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,High,8.4
75,Unauthorized Model Control,Causes service disruption or exposes confidential model parameters.,Session Management,Causes service disruption or exposes confidential model parameters.,Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Low,5.7
76,Policy Bypass via Prompt Tampering,"Enables adversaries to manipulate responses, compromising integrity.",Adversarial Attack,Allows attackers to extract sensitive data or alter model behavior.,Using adversarial inputs to exploit weak error handling mechanisms.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Critical,9.1
77,Backend API Overload,"Enables adversaries to manipulate responses, compromising integrity.",Access Control,Causes service disruption or exposes confidential model parameters.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,6.7
78,Model Parameter Enumeration,Allows attackers to extract sensitive data or alter model behavior.,Access Control,"Enables adversaries to manipulate responses, compromising integrity.",Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,High,6.5
79,Cache Poisoning of Model Responses,"Can lead to unauthorized access, data leakage, or system misbehavior.",Configuration Error,"Results in unintentional outputs, breaching privacy or security policies.",Submitting repeated requests to extract sensitive data from the model.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Critical,9.2
80,Adversarial Token Substitution,"Enables adversaries to manipulate responses, compromising integrity.",Resource Exhaustion,Causes service disruption or exposes confidential model parameters.,Using adversarial inputs to exploit weak error handling mechanisms.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Low,4.2
81,High-Volume Querying for Data Extraction,Causes service disruption or exposes confidential model parameters.,Access Control,"Enables adversaries to manipulate responses, compromising integrity.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Critical,9
82,Unfiltered API Call Exploitation,Allows attackers to extract sensitive data or alter model behavior.,Configuration Error,"Enables adversaries to manipulate responses, compromising integrity.",Submitting repeated requests to extract sensitive data from the model.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,5
83,Role-Based Model Hijacking,Allows attackers to extract sensitive data or alter model behavior.,Data Leakage,Causes service disruption or exposes confidential model parameters.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,7.2
84,Model Endpoint Probing,"Enables adversaries to manipulate responses, compromising integrity.",Session Management,"Can lead to unauthorized access, data leakage, or system misbehavior.",Injecting backdoor prompts during inference to control outputs.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Low,9.4
85,Training Data Inference,"Can lead to unauthorized access, data leakage, or system misbehavior.",Output Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Using crafted tokens to alter LLM responses significantly.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,9.8
86,Output Spoofing,Causes service disruption or exposes confidential model parameters.,Access Control,"Can lead to unauthorized access, data leakage, or system misbehavior.",Submitting repeated requests to extract sensitive data from the model.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,High,5.7
87,Unauthorized Model Control,"Results in unintentional outputs, breaching privacy or security policies.",Session Management,Causes service disruption or exposes confidential model parameters.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,7.5
88,Model Endpoint Probing,Causes service disruption or exposes confidential model parameters.,Output Manipulation,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using adversarial inputs to exploit weak error handling mechanisms.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Critical,4.1
89,Model Endpoint Probing,"Results in unintentional outputs, breaching privacy or security policies.",Output Manipulation,Causes service disruption or exposes confidential model parameters.,Submitting repeated requests to extract sensitive data from the model.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Low,9.1
90,Overfitting Exploit,"Can lead to unauthorized access, data leakage, or system misbehavior.",Model Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Hijacking sessions by reusing old tokens in LLM-based systems.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Medium,6
91,Misleading Response Injection,"Results in unintentional outputs, breaching privacy or security policies.",Data Leakage,"Can lead to unauthorized access, data leakage, or system misbehavior.",Submitting repeated requests to extract sensitive data from the model.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Critical,4.7
92,Contextual Misdirection,"Enables adversaries to manipulate responses, compromising integrity.",Configuration Error,"Enables adversaries to manipulate responses, compromising integrity.",Using adversarial inputs to exploit weak error handling mechanisms.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,Medium,9.6
93,LLM Behavior Injection,Causes service disruption or exposes confidential model parameters.,Data Leakage,Causes service disruption or exposes confidential model parameters.,Using adversarial inputs to exploit weak error handling mechanisms.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,High,6.7
94,Covert Prompt Injection,"Can lead to unauthorized access, data leakage, or system misbehavior.",Access Control,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using crafted tokens to alter LLM responses significantly.,"Implement rate limiting, input sanitization, and robust authentication mechanisms.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,High,4.7
95,Data Exfiltration via LLM Outputs,"Enables adversaries to manipulate responses, compromising integrity.",Data Leakage,Allows attackers to extract sensitive data or alter model behavior.,Using crafted tokens to alter LLM responses significantly.,"Use adversarial training, dynamic prompt filtering, and secure session handling.","GPT-3, GPT-4, PaLM, LLaMA",OWASP AI Security Guide,Critical,7.6
96,Model Overload via Crafted Prompts,Allows attackers to extract sensitive data or alter model behavior.,Adversarial Attack,"Can lead to unauthorized access, data leakage, or system misbehavior.",Using crafted tokens to alter LLM responses significantly.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Medium,8.9
97,Unauthorized Model Access,Allows attackers to extract sensitive data or alter model behavior.,Adversarial Attack,Allows attackers to extract sensitive data or alter model behavior.,Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",MITRE ATT&CK for AI,High,9.5
98,Internal State Manipulation,"Enables adversaries to manipulate responses, compromising integrity.",Session Management,"Results in unintentional outputs, breaching privacy or security policies.",Hijacking sessions by reusing old tokens in LLM-based systems.,"Apply data encryption, token rotation, and continuous monitoring of API endpoints.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,Critical,4.6
99,Backdoor Trigger Injection,Causes service disruption or exposes confidential model parameters.,Session Management,"Can lead to unauthorized access, data leakage, or system misbehavior.",Hijacking sessions by reusing old tokens in LLM-based systems.,Utilize model explainability techniques to detect unexpected behaviors.,"GPT-3, GPT-4, PaLM, LLaMA",ISO/IEC 27001,Low,8
100,Model Parameter Inference,"Enables adversaries to manipulate responses, compromising integrity.",API Misuse,"Enables adversaries to manipulate responses, compromising integrity.",Injecting backdoor prompts during inference to control outputs.,"Employ role-based access control, endpoint security, and model validation processes.","GPT-3, GPT-4, PaLM, LLaMA",NIST AI RMF,High,6
