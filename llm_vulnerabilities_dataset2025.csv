ID,Vulnerability Name,Description,Category,Severity Level,Risk Score,Affected Models,Impact,Exploit Examples,Mitigation Strategies,Mitigation Tools,Source,Affected Deployment Environments,Detection Difficulty,Exploitation Complexity,Remediation Cost,Compliance Implications,Ethical Implications
1,Unauthorized Access,"Improper access controls allow attackers to alter or control model behavior.",Input Manipulation,Low,4.5,"GPT-3, GPT-4, PaLM, LLaMA","Potential service disruption and unauthorized data manipulation.","Misconfigured access permissions enabled unauthorized access in a social media platform.","Implement robust authentication and authorization; audit and update access controls regularly.","IAM systems like Okta or AWS IAM","OWASP LLM AI Security Guide","Cloud, On-premise",Low,Low,Low,"May breach basic security standards","Limited, but potential privacy issues"
2,Weak Data Governance,"Poor data management practices lead to tampering or corruption of model data.",Input Manipulation,High,7.7,"GPT-3, GPT-4, PaLM, LLaMA","Weakens overall security posture and data integrity.","Equifax breach due to inadequate protection of sensitive data.","Establish strict data governance policies with data classification and encryption.","Data governance platforms like Collibra or Informatica","MITRE ATT&CK for AI","Cloud, Hybrid",Medium,Medium,Medium,"Could breach GDPR/other regulations","High potential for privacy violations"
3,Unvalidated Inputs,"Lack of proper input validation can lead to injection attacks and unauthorized data disclosure.",Input Manipulation,Medium,8.1,"GPT-3, GPT-4, PaLM, LLaMA","Can cause data tampering and model corruption.","SQL injection attacks in vulnerable web applications.","Implement comprehensive input validation and sanitization using parameterized queries.","WAFs like ModSecurity","ISO/IEC 27001","Web, Cloud",Medium,Low,Low,"May violate PCI-DSS if payment data is involved","Risk of exposing user data"
4,Weak Model Parameter Encryption,"Storing model parameters without encryption allows attackers to extract or misuse sensitive data.",Model Exploitation,Critical,4.7,"GPT-3, GPT-4, PaLM, LLaMA","May allow extraction of proprietary information and unauthorized model control.","Proprietary models leaked due to unencrypted storage.","Encrypt model parameters at rest and in transit; use secure key management.","Encryption libraries like PyCrypto or AWS KMS","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"Non-compliance with data protection regulations","High risk if sensitive training data is exposed"
5,Improper Rate Limiting,"Insufficient API rate limiting can lead to denial-of-service attacks and data manipulation.",API Security,High,8.8,"GPT-3, GPT-4, PaLM, LLaMA","Potential service disruption and system overload.","GitHubâ€™s 2018 DDoS attack due to inadequate rate limiting.","Enforce strict rate limiting on APIs; continuously monitor traffic.","API gateways like Kong or AWS API Gateway","ISO/IEC 27001","Cloud, Hybrid",Low,Low,Low,"May conflict with SLAs and uptime requirements","Could affect service fairness"
6,Prompt Injection,"Manipulation of prompts can cause models to generate unauthorized or sensitive outputs.",Adversarial Attack,High,9.1,"GPT-3, GPT-4, PaLM, LLaMA","Leads to inaccurate outputs and potential leakage of confidential data.","Chatbots tricked into revealing confidential information via manipulated prompts.","Use strict prompt validation, sanitize inputs, and restrict output capabilities.","Input validation libraries and AI safety frameworks","NIST AI RMF","Cloud, On-premise, Web",Medium,Medium,Medium,"Could violate privacy laws","High risk of misinformation"
7,Insufficient Privacy Controls,"Lack of robust privacy measures results in the exposure of personal data and sensitive information.",Access Control,High,8.8,"GPT-3, GPT-4, PaLM, LLaMA","Increases risk of privacy breaches and data leaks.","Netflix Prize incident: re-identification of anonymized data.","Implement robust data anonymization and pseudonymization; enforce strict privacy policies.","Privacy management tools like OneTrust or Privitar","NIST AI RMF","Cloud, On-premise",High,Low,High,"Non-compliance with GDPR/CCPA","Significant privacy concerns for individuals"
8,Data Poisoning During Training,"Introduction of malicious data into training sets that skews model behavior towards attacker goals.",Input Manipulation,Critical,9.0,"GPT-3, GPT-4, PaLM, LLaMA","Can cause systemic errors and introduce hidden backdoors.","Adversaries injecting biased or malicious data into training datasets.","Employ rigorous data validation, provenance tracking, and robust training protocols.","Data validation tools and secure data pipelines","MITRE ATT&CK for AI","Cloud, Hybrid",High,High,High,"Violates data integrity standards and legal requirements","High potential for widespread harm"
9,Supply Chain Attack on LLM Components,"Compromise of third-party components or libraries can introduce vulnerabilities into the system.",Supply Chain,Critical,9.3,"GPT-3, GPT-4, PaLM, LLaMA","May introduce malicious code or systemic vulnerabilities via compromised components.","Exploitation of compromised libraries or pre-trained models.","Vet all third-party components; continuously monitor and verify integrity.","SIEM systems, code analysis tools","MITRE ATT&CK for AI","Cloud, On-premise",High,High,High,"May breach supply chain security regulations","High risk to overall system trust"
10,Biased Output Propagation,"Unintended biases in model outputs can reinforce stereotypes and lead to unfair outcomes.",Ethical & Social,High,8.0,"GPT-3, GPT-4, PaLM, LLaMA","Can cause reputational damage and legal risks, while harming affected groups.","Instances of bias in automated hiring or lending decisions.","Implement bias detection and correction; perform regular audits with diverse datasets.","Bias mitigation toolkits like IBM AI Fairness 360 or Fairlearn","OWASP LLM AI Security Guide","Cloud, On-premise, Web",Medium,Low,Medium,"May violate anti-discrimination laws","Significant ethical and societal concerns"
11,Unrestricted Function Calls,"Allowing an LLM to execute arbitrary functions may result in execution of malicious code.",Privacy Violation,Medium,8.2,"GPT-3, GPT-4, PaLM, LLaMA","Could result in unauthorized system commands and data breaches.","Instances where models executed unintended system commands.","Restrict callable functions; implement strict code execution policies and sandboxing.","Sandbox environments like Docker; function whitelisting solutions","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Medium,Medium,"May breach operational security guidelines","High risk to user data integrity"
12,Poor Model Monitoring,"Lack of continuous performance monitoring may allow model drift to go undetected.",Data Leakage,High,7.1,"GPT-3, GPT-4, PaLM, LLaMA","Leads to degradation in performance and potential security breaches.","A fraud detection model becoming ineffective over time.","Set up continuous monitoring and alerting; schedule regular model retraining.","Monitoring tools like Prometheus and Evidently AI","ISO/IEC 27001","Cloud, Hybrid",Medium,Low,Medium,"Could result in regulatory non-compliance if model performance drops","May lead to unintended decisions impacting users"
13,Undetected Model Modification,"Subtle alterations in a model that cause deviations in outputs or behavior.",API Security,Medium,6.2,"GPT-3, GPT-4, PaLM, LLaMA","Risks data integrity and reliable performance.","Instances where slight model alterations led to wrong outputs in critical systems.","Implement integrity checks and cryptographic version controls; use hash verifications.","Version control systems like Git, checksum tools","NIST AI RMF","Cloud, On-premise",Medium,Medium,Medium,"May breach internal security protocols","Risk of propagating inaccurate outputs"
14,Insecure Data Storage,"Storing sensitive data without proper encryption exposes it to theft.",Model Manipulation,Critical,5.4,"GPT-3, GPT-4, PaLM, LLaMA","Exposes sensitive information and can lead to widespread data breaches.","The 2012 LinkedIn password leak due to unencrypted storage.","Encrypt data at rest and in transit; use secure storage solutions.","Encryption tools like BitLocker or AWS Encryption Services","MITRE ATT&CK for AI","Cloud, On-premise",High,Low,Medium,"Violates data protection regulations","Severe privacy risks"
15,Training Data Replay,"Excessive exposure of training data may allow attackers to reconstruct sensitive information.",Input Manipulation,Low,5.1,"GPT-3, GPT-4, PaLM, LLaMA","May expose confidential training data.","Reconstruction of training data through repeated queries.","Limit output detail and implement differential privacy techniques.","Differential privacy libraries like TensorFlow Privacy","NIST AI RMF","Cloud, Hybrid",High,Medium,Medium,"May breach data minimization principles","Potential for personal data exposure"
16,Reinforcement Loop Exploitation,"Manipulation of feedback loops causes models to reinforce incorrect behavior.",Input Manipulation,Low,9.0,"GPT-3, GPT-4, PaLM, LLaMA","Can result in skewed recommendations or unintended model behavior.","Exploitation of feedback mechanisms in recommendation engines.","Monitor and adjust feedback channels; implement human oversight.","AI moderation services and feedback monitoring tools","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,High,Medium,"Could lead to regulatory scrutiny if misused","May cause ethical issues in automated decision-making"
17,Incorrect Model Configuration,"Misconfigured settings expose models to unauthorized actions or data leakage.",Model Exploitation,Medium,7.8,"GPT-3, GPT-4, PaLM, LLaMA","Can cause operational failures and data exposure.","Debug mode left enabled in production systems.","Follow secure configuration management practices; disable debug modes in production.","Configuration management tools like Ansible or Chef","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Low,Low,"Could violate internal IT policies","May result in unintended disclosures"
18,Cache Poisoning,"Malicious data inserted into cache can disrupt or corrupt model responses.",Output Manipulation,Critical,8.0,"GPT-3, GPT-4, PaLM, LLaMA","Alters cached outputs leading to erroneous model behavior.","DNS cache poisoning attacks provide a similar threat model.","Validate cache integrity; implement robust cache eviction policies.","Secure caching solutions like Redis with security hardening","NIST AI RMF","Cloud, On-premise",High,Medium,Medium,"May conflict with data integrity standards","Risk of widespread misinformation"
19,Tampered Model Files,"Downloading or using altered model files results in compromised performance.",API Security,Critical,4.8,"GPT-3, GPT-4, PaLM, LLaMA","Leads to unauthorized modifications and potential malware execution.","Incidents of malicious code in downloaded open-source models.","Download models only from trusted sources; verify file integrity with checksums.","Checksum tools and trusted repositories like GitHub","ISO/IEC 27001","Cloud, On-premise",High,Medium,Medium,"May breach software supply regulations","High risk to system trust"
20,External System Integration Risks,"Integrations with untrusted third-party systems introduce vulnerabilities.",Model Manipulation,Low,9.7,"GPT-3, GPT-4, PaLM, LLaMA","May allow attackers to indirectly control or manipulate model outputs.","Supply chain attacks via compromised integrations.","Vet third-party systems thoroughly; monitor all external interactions.","SIEM systems like Splunk; network monitoring tools","NIST ATT&CK for AI","Cloud, Hybrid",High,High,High,"Could violate cross-industry compliance mandates","Significant risk to overall system security"
21,Logging Failures,"Inadequate logging practices can obscure security incidents or expose sensitive data.",API Security,Low,8.4,"GPT-3, GPT-4, PaLM, LLaMA","Might miss critical security events or leak personal data.","Plaintext logging of credit card numbers in debug logs.","Implement secure logging practices with sensitive data masking; review logs regularly.","ELK Stack with security configurations","MITRE ATT&CK for AI","Cloud, On-premise",Medium,Low,Low,"May breach PCI or other regulatory requirements","Potential for inadvertent data exposure"
22,Prompt Injection (Advanced),"Advanced prompt injection techniques can lead to highly targeted manipulations.",Output Manipulation,Critical,5.4,"GPT-3, GPT-4, PaLM, LLaMA","Can result in highly sensitive information leakage.","Complex prompt injection attacks used in adversarial testing.","Implement multi-layered prompt sanitization; restrict sensitive outputs.","Advanced input validation frameworks and human review","OWASP LLM AI Security Guide","Cloud, On-premise, Web",High,High,High,"Could breach multiple regulatory frameworks","High risk of targeted misinformation"
23,Response Timing Analysis,"Exploitation of system response times to infer sensitive internal data.",Model Exploitation,Low,5.6,"GPT-3, GPT-4, PaLM, LLaMA","May reveal data about system internals or encryption keys.","Timing attacks similar to those on cryptographic systems.","Implement random delays and normalize response times.","Application performance monitoring (APM) tools","MITRE ATT&CK for AI","Cloud, On-premise",Medium,High,Medium,"May violate confidentiality requirements","Can lead to serious privacy breaches"
24,Context Injection Attacks,"Injecting malicious context into multi-turn interactions to alter outputs.",Adversarial Attack,Medium,7.0,"GPT-3, GPT-4, PaLM, LLaMA","Results in manipulated conversation context and inaccurate responses.","Similar to prompt injection but focused on session history manipulation.","Validate and sanitize session context; limit context length.","Context validation libraries and AI safety guidelines","NIST AI RMF","Cloud, Web",Medium,Medium,Medium,"May contravene data integrity standards","Risk of spreading misinformation"
25,Improper Access Control,"Failure to enforce strict access control leads to unauthorized data disclosure.",Adversarial Attack,High,4.1,"GPT-3, GPT-4, PaLM, LLaMA","Can allow unauthorized users to access and manipulate data.","Exploitation of weak API token validations.","Implement role-based access control (RBAC) and secure token management.","Access control solutions like AWS IAM or Azure AD","MITRE ATT&CK for AI","Cloud, On-premise",Medium,Medium,Low,"Could breach access regulations","Risk of user data exposure"
26,Interactive Feedback Exploitation,"Manipulation of interactive feedback loops alters long-term model behavior.",Adversarial Attack,High,8.4,"GPT-3, GPT-4, PaLM, LLaMA","Leads to gradual bias or drift in model responses.","Exploitation of live user feedback in chatbots or recommendation systems.","Implement robust feedback validation; monitor for anomalous patterns.","Feedback monitoring systems and anomaly detectors","NIST AI RMF","Cloud, Hybrid",High,High,High,"May breach internal quality controls","Ethically concerning if used to manipulate opinions"
27,Incorrect Session Management,"Weak session management allows attackers to hijack active sessions.",API Security,Critical,7.6,"GPT-3, GPT-4, PaLM, LLaMA","Exposes user sessions leading to unauthorized actions.","Session hijacking attacks similar to web application breaches.","Enforce secure, random session identifiers and automatic session invalidation.","Secure session management in frameworks like Express.js with Helmet","MITRE ATT&CK for AI","Web, Cloud",Medium,Medium,Medium,"May breach privacy and data protection laws","Significant risk to personal data"
28,Backend Server Exploitation,"Vulnerabilities in backend systems supporting LLMs can be exploited to control models.",Input Manipulation,Low,9.2,"GPT-3, GPT-4, PaLM, LLaMA","May provide attackers with an entry point into the LLM environment.","Exploitation of unpatched server vulnerabilities in API servers.","Keep backend servers updated; deploy firewalls and intrusion detection systems.","IDS tools like Snort and OSSEC","NIST AI RMF","On-premise, Cloud",High,High,High,"Could violate IT security standards","High risk to overall system integrity"
29,Overfitting Exploitation,"Models that overfit may unintentionally reveal sensitive training data.",Input Manipulation,High,6.2,"GPT-3, GPT-4, PaLM, LLaMA","May leak confidential training data when queried in certain ways.","Attackers extracting training data from overfitted models.","Use regularization techniques and validate on unseen data.","Machine learning libraries like scikit-learn or TensorFlow","OWASP LLM AI Security Guide","Cloud, Hybrid",High,Medium,Medium,"Could breach data privacy standards","Risk of unintended data disclosure"
30,Improper Input Filtering,"Failure to filter user inputs can allow injection attacks and code execution.",Model Exploitation,Critical,9.4,"GPT-3, GPT-4, PaLM, LLaMA","May lead to severe injection attacks and unauthorized actions.","Exploitation through malicious payloads in input fields.","Implement comprehensive input filtering using allowlists and rigorous sanitization.","Security libraries like OWASP ESAPI","NIST AI RMF","Web, Cloud",High,High,High,"Could breach multiple regulatory mandates","Severe ethical and operational risks"
31,Data Retention Issues,"Storing data longer than necessary increases risk of breaches and misuse.",Input Manipulation,Low,8.2,"GPT-3, GPT-4, PaLM, LLaMA","May lead to exposure of obsolete yet sensitive information.","Breaches where old user data was accessed due to lax deletion policies.","Implement automated data lifecycle management; enforce retention policies.","Data management tools like Apache Atlas","OWASP LLM AI Security Guide","Cloud, Hybrid",Medium,Medium,Medium,"May violate GDPR data minimization principles","Ethical concerns over user privacy"
32,Manipulative Model Retraining,"Feeding manipulated data during retraining can shift model behavior undesirably.",Configuration Error,Critical,6.5,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to biased or malicious outputs over time.","Incident similar to the Tay chatbot learning offensive behavior.","Validate and filter training data; monitor retraining processes rigorously.","Data validation tools and model monitoring platforms like Weights & Biases","NIST AI RMF","Cloud, Hybrid",High,High,High,"May breach ethical AI guidelines","Severe impact on public trust"
33,Limited Model Generalization,"A model trained on insufficient data may fail in real-world applications.",Model Exploitation,Critical,5.7,"GPT-3, GPT-4, PaLM, LLaMA","Leads to poor performance and potential misclassifications.","Facial recognition systems failing on diverse populations.","Ensure diverse and comprehensive training data; use cross-validation techniques.","Data augmentation tools and ML frameworks like scikit-learn","NIST AI RMF","Cloud, Hybrid",Medium,Medium,Medium,"Could violate fairness regulations","Ethical concerns regarding bias"
34,Session Hijacking,"Attackers exploit weak session handling to impersonate legitimate users.",Configuration Error,High,4.0,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to unauthorized access and data tampering.","Session hijacking observed in several web application attacks.","Implement secure session management; use HTTPS and secure cookies.","Web frameworks with secure session support like Express.js with Helmet","MITRE ATT&CK for AI","Web, Cloud",Medium,Medium,Low,"May breach privacy laws","Significant risk to personal data"
35,Unrestricted LLM Functions (Limited),"Allowing LLMs to access non-essential functions increases risk of misuse.",Access Control,Medium,4.2,"GPT-3, GPT-4, PaLM, LLaMA","May result in unauthorized function execution.","Instances where models executed functions outside intended scope.","Limit LLM functionalities to essential operations; sandbox execution environments.","Secure sandbox solutions like Docker containers","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Medium,Medium,"Could impact compliance with operational controls","Risk of misuse and unintended behavior"
36,Lack of Governance,"Absence of proper AI governance can lead to ethical and legal compliance issues.",Output Manipulation,Critical,4.8,"GPT-3, GPT-4, PaLM, LLaMA","May allow deployment of biased or non-compliant models.","Incidents of biased AI decisions due to poor governance.","Establish AI governance frameworks; conduct regular audits and compliance reviews.","Governance platforms like IBM OpenPages or SAS Compliance Solutions","MITRE ATT&CK for AI","Cloud, Hybrid",High,Medium,High,"May violate multiple legal frameworks","High ethical implications"
37,Exploitability of LLM Integrations,"Insecure integration with external systems exposes LLMs to additional vulnerabilities.",Access Control,Low,5.6,"GPT-3, GPT-4, PaLM, LLaMA","May allow attackers to inject malicious code through integrations.","Exploits where third-party API integrations were used to compromise systems.","Secure integration points with authentication and rigorous input validation.","API security tools and middleware for sanitization","NIST AI RMF","Cloud, Hybrid",Medium,Medium,Medium,"Could breach supply chain regulations","Risk of systemic vulnerabilities"
38,Hidden Feedback Channels,"Undocumented feedback loops may be exploited to alter model outputs.",Model Exploitation,High,6.9,"GPT-3, GPT-4, PaLM, LLaMA","May result in covert manipulation of model behavior.","Exploitation of hidden feedback in recommendation systems.","Monitor and validate all feedback channels; restrict access to feedback mechanisms.","Feedback monitoring and anomaly detection tools","NIST AI RMF","Cloud, On-premise",High,High,Medium,"Could lead to compliance issues if misused","Ethically concerning due to hidden manipulation"
39,Response Manipulation,"Attackers alter model outputs to deliver misleading or harmful information.",Adversarial Attack,High,9.5,"GPT-3, GPT-4, PaLM, LLaMA","Results in generation of incorrect or malicious responses.","Manipulation of outputs in systems generating public information.","Implement output verification processes and human-in-the-loop review.","Output validation libraries and human oversight mechanisms","MITRE ATT&CK for AI","Cloud, On-premise",High,High,High,"May breach trust and legal obligations","High ethical risk and potential for harm"
40,Invisible Prompt Attack,"Embedding hidden prompts in user input alters model behavior without detection.",Model Manipulation,Medium,8.6,"GPT-3, GPT-4, PaLM, LLaMA","May covertly manipulate model responses.","Invisible prompt attacks observed in controlled experiments.","Filter and sanitize all inputs; deploy techniques to detect hidden content.","Input validation libraries and content filtering tools","NIST AI RMF","Cloud, On-premise, Web",High,Medium,Medium,"Could violate content integrity standards","Ethical concerns due to hidden manipulation"
41,Overfitting Exploitation (Variant),"Excessive overfitting may lead models to inadvertently memorize sensitive data.",Input Manipulation,High,6.3,"GPT-3, GPT-4, PaLM, LLaMA","May result in extraction of training data.","Instances where overfitted models leaked training examples under specific queries.","Implement regularization, early stopping, and robust evaluation on unseen data.","ML libraries with regularization support like TensorFlow","ISO/IEC 27001","Cloud, Hybrid",High,Medium,Medium,"Could breach data privacy standards","Risk of exposing confidential training data"
42,Unrestricted Function Calls (Advanced),"Allowing arbitrary function calls increases the risk of executing dangerous operations.",Privacy Violation,High,7.3,"GPT-3, GPT-4, PaLM, LLaMA","May result in unauthorized code execution and data loss.","Similar to previous unrestricted call issues but in complex environments.","Limit allowed functions strictly; use hardened execution sandboxes.","Function whitelisting and secure execution environments","OWASP LLM AI Security Guide","Cloud, On-premise",High,High,High,"May violate strict operational controls","High ethical and security risk"
43,Logging Failures (Enhanced),"Incomplete logging may prevent detection of security incidents and hide sensitive data.",Data Leakage,Medium,5.0,"GPT-3, GPT-4, PaLM, LLaMA","Can obscure intrusion attempts and expose sensitive logs.","Examples include logging sensitive user information in plaintext.","Implement centralized logging with data masking and regular audits.","Logging frameworks with secure configurations like ELK Stack","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Low,Medium,"Could breach data retention and privacy regulations","Risk of significant data exposure"
44,Context Leakage via Multi-Turn Interactions,"Accumulated context in conversations can reveal sensitive historical data.",Data Leakage,High,8.7,"GPT-3, GPT-4, PaLM, LLaMA","May expose confidential conversation history.","Multi-turn chat sessions inadvertently disclosing personal data.","Limit context length and apply anonymization to conversation histories.","Session management systems and context-aware filters","OWASP LLM AI Security Guide","Cloud, Hybrid",High,Medium,High,"May violate data protection regulations","High risk to personal privacy"
45,Incorrect Model Configuration (Extended),"Misconfigurations expose models to security and performance risks.",Model Exploitation,Medium,7.8,"GPT-3, GPT-4, PaLM, LLaMA","Leads to debug information leaks and insecure operations.","Incidents of models running in debug mode in production.","Enforce configuration management best practices; use environment-based settings.","Configuration management tools like Chef or Puppet","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Low,Low,"May violate internal security policies","Risk of exposing internal details"
46,Backend API Exploitation,"Exploitation of poorly secured backend APIs can lead to model control.",API Security,Critical,8.6,"GPT-3, GPT-4, PaLM, LLaMA","May allow attackers to manipulate model behavior via APIs.","Exploitation of insecure API endpoints in financial services.","Enforce strong API authentication, rate limiting, and input validation.","API security gateways like AWS API Gateway or Kong","MITRE ATT&CK for AI","Cloud, Hybrid",Medium,Medium,Medium,"Could breach financial data regulations","High operational and ethical risk"
47,Manipulative Model Incentivization,"Attackers alter reward signals in reinforcement learning to skew outcomes.",Adversarial Attack,Low,4.1,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to biased and manipulated model incentives.","Manipulation in gamified systems to promote unintended outcomes.","Design robust reward functions and continuously monitor agent behaviors.","Reinforcement learning frameworks with monitoring like OpenAI Gym","ISO/IEC 27001","Cloud, Hybrid",Medium,Medium,Low,"May violate fairness guidelines","Ethically concerning if used to manipulate outcomes"
48,Input Inference Attacks,"Attackers infer sensitive input information by analyzing model outputs.",API Security,Medium,5.8,"GPT-3, GPT-4, PaLM, LLaMA","May expose details about private training data.","Inference attacks used to deduce membership of training datasets.","Apply differential privacy and limit the granularity of outputs.","Privacy-preserving ML tools like TensorFlow Privacy","MITRE ATT&CK for AI","Cloud, Hybrid",High,Medium,Medium,"Could breach data privacy standards","High risk of personal data exposure"
49,Erroneous LLM Responses,"Generation of misleading or factually incorrect responses by the model.",Access Control,Medium,8.3,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to poor decision-making and misinformation.","Instances where AI-generated responses led to business errors.","Implement human-in-the-loop review for critical outputs and use verification mechanisms.","AI output validation tools and feedback systems","MITRE ATT&CK for AI","Cloud, On-premise",Medium,Low,Medium,"May violate consumer protection standards","High ethical concerns over misinformation"
50,Model Entanglement Issues,"Interdependencies between model components lead to unpredictable behavior.",Adversarial Attack,High,8.4,"GPT-3, GPT-4, PaLM, LLaMA","May result in cascading failures and erratic outputs.","Complex models where one module's change adversely affects others.","Design modular architectures and test components independently.","Model testing frameworks and modular design patterns","OWASP LLM AI Security Guide","Cloud, Hybrid",High,High,High,"Could impact system reliability standards","Ethical concerns regarding reliability"
51,Unrestricted Function Calls (Extended),"Allowing excessive function access increases the attack surface for code injection.",Privacy Violation,Medium,8.2,"GPT-3, GPT-4, PaLM, LLaMA","May lead to unauthorized system modifications.","Instances of arbitrary function calls causing system compromise.","Implement strict function call restrictions and use sandboxing.","Function whitelisting and secure code execution environments","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Medium,Medium,"Could breach operational and data security policies","High ethical risk"
52,Overfitting Exploitation (Alternate),"Models memorizing training data may inadvertently disclose sensitive content.",Input Manipulation,High,6.2,"GPT-3, GPT-4, PaLM, LLaMA","Risk of exposing proprietary training data.","Repeated queries extracting exact training instances from an overfitted model.","Employ regularization, dropout, and comprehensive testing on unseen data.","ML frameworks with built-in regularization options","OWASP LLM AI Security Guide","Cloud, Hybrid",High,Medium,Medium,"May violate intellectual property rights","Risk of sensitive information leakage"
53,Erroneous Data Aggregation,"Improper aggregation of model outputs can lead to disclosure of sensitive patterns.",Data Leakage,Medium,7.5,"GPT-3, GPT-4, PaLM, LLaMA","May expose aggregated data trends leading to re-identification.","Inadvertent aggregation in analytics tools exposing detailed user patterns.","Implement data aggregation with strict anonymization and thresholding.","Data masking and aggregation tools","ISO/IEC 27001","Cloud, Hybrid",Medium,Medium,Medium,"Could violate data protection standards","Ethically concerning if personal data is re-identified"
54,Session Hijacking (Advanced),"Advanced session hijacking using stolen tokens to impersonate users.",Adversarial Attack,Critical,5.0,"GPT-3, GPT-4, PaLM, LLaMA","Results in complete session takeover and unauthorized actions.","Advanced token theft used in high-profile web application breaches.","Enforce token expiration, secure storage, and multifactor authentication.","Secure session management frameworks and HTTPS enforcement","OWASP LLM AI Security Guide","Web, Cloud",Medium,Medium,Low,"May breach privacy and authentication regulations","High risk to user trust"
55,Leakage of Inferred Attributes,"Models inferring sensitive attributes from benign inputs expose personal data.",Privacy Violation,Critical,6.9,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to unauthorized disclosure of personal characteristics.","Inference of health conditions or demographics from simple queries.","Limit the scope of inference; implement ethical AI guidelines and bias audits.","Fairness and privacy assessment tools like IBM AI Fairness 360","NIST AI RMF","Cloud, Hybrid",High,Medium,Medium,"May breach privacy and discrimination laws","Severe ethical and societal concerns"
56,Prompt Injection (Variant),"Variant prompt injection techniques lead to exposure of sensitive internal data.",Output Manipulation,Medium,7.5,"GPT-3, GPT-4, PaLM, LLaMA","May cause unintended disclosure of confidential data.","Attackers using subtle prompt variations to trick models.","Implement robust prompt sanitization and contextual awareness checks.","Advanced prompt filtering frameworks and periodic reviews","NIST AI RMF","Cloud, On-premise, Web",Medium,Medium,Medium,"Could breach internal data protection policies","Risk of misinformation and data leakage"
57,Improper Model Scaling,"Failure to scale models properly under high load leads to outages and vulnerabilities.",Output Manipulation,Low,8.3,"GPT-3, GPT-4, PaLM, LLaMA","Can cause denial-of-service under peak conditions.","Overloading models during peak usage leading to unresponsiveness.","Plan and test for scalability; implement auto-scaling and load balancing.","Performance testing tools like JMeter; cloud auto-scaling services","MITRE ATT&CK for AI","Cloud, Hybrid",Medium,Medium,Medium,"May breach service level agreements","Could affect fairness in service access"
58,Unrestricted Function Calls (Second Instance),"Allowing arbitrary code execution poses significant security threats.",Privacy Violation,High,7.3,"GPT-3, GPT-4, PaLM, LLaMA","May enable attackers to run unauthorized code.","Similar to previous function call vulnerabilities in sensitive contexts.","Restrict function calls and enforce strict execution policies.","Sandboxing and function whitelisting solutions","OWASP LLM AI Security Guide","Cloud, On-premise",High,High,High,"Violates best practices in secure coding","High ethical and security implications"
59,Hidden Feedback Channels (Alternate),"Covert feedback paths may be exploited to subtly alter model outputs.",Model Exploitation,High,6.9,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to unauthorized behavior modification.","Undocumented feedback mechanisms in recommendation systems.","Monitor, document, and secure all feedback channels rigorously.","Feedback monitoring systems and SIEM tools","NIST AI RMF","Cloud, On-premise",High,Medium,Medium,"Could breach internal compliance guidelines","Ethically concerning due to covert manipulation"
60,Weak Protection for Sensitive Outputs,"Failure to secure outputs can result in exposure of confidential information.",Access Control,High,5.5,"GPT-3, GPT-4, PaLM, LLaMA","May leak sensitive outputs in AI-generated reports.","Instances of sensitive information appearing in public analytics.","Implement output filtering and strict access control on outputs.","Data masking and secure reporting systems","OWASP LLM AI Security Guide","Cloud, On-premise",Medium,Medium,Medium,"May breach privacy regulations","Risk of unintended data disclosure"
61,Weak Session Management,"Poor session management allows for session fixation and hijacking.",API Security,Critical,7.6,"GPT-3, GPT-4, PaLM, LLaMA","Exposes user sessions to hijacking and unauthorized actions.","Session fixation attacks observed in insecure web applications.","Use secure, random session identifiers and enforce session timeouts.","Web frameworks with secure session features","MITRE ATT&CK for AI","Web, Cloud",Medium,Medium,Medium,"May violate data protection regulations","High risk to user privacy"
62,Unauthorized Access (Repeated Scenario),"Repetition of default credentials and weak passwords leads to repeated unauthorized access.",Data Leakage,Low,4.2,"GPT-3, GPT-4, PaLM, LLaMA","Leads to recurring unauthorized access incidents.","Default account misuse in legacy systems.","Enforce strong password policies; disable or change default accounts.","Password management tools and security policy enforcement","ISO/IEC 27001","Cloud, On-premise",Low,Low,Low,"May breach organizational security policies","Low, but persistent risk"
63,Response Timing Analysis (Alternate),"Analyzing system response times to infer sensitive internal information.",Model Exploitation,Low,5.6,"GPT-3, GPT-4, PaLM, LLaMA","May leak information about internal processing or encryption.","Timing attacks similar to those on secure cryptographic implementations.","Normalize response times; add random delays to mitigate timing differences.","APM tools for detecting anomalies","MITRE ATT&CK for AI","Cloud, On-premise",Medium,High,Medium,"Could breach confidentiality standards","Potential for severe privacy impact"
64,Context Injection Attacks (Alternate),"Injecting context into multi-turn interactions can cause model misbehavior.",Data Leakage,Critical,4.3,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to compromised conversation integrity.","Attacks where malicious context altered chatbot responses.","Validate and sanitize contextual data; limit context retention.","Context validation libraries and AI safety guidelines","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"May violate data protection policies","Risk of misleading outputs"
65,Model Drift,"Gradual degradation of model performance due to evolving data patterns.",API Security,Medium,6.7,"GPT-3, GPT-4, PaLM, LLaMA","Leads to inaccurate predictions and degraded performance over time.","Models that become outdated due to changing trends.","Implement continuous model monitoring and schedule periodic retraining.","Monitoring tools like Evidently AI or SageMaker Model Monitor","NIST AI RMF","Cloud, Hybrid",Medium,Low,Medium,"Could breach service quality agreements","Ethically concerning if decisions are based on outdated data"
66,Response Manipulation (Alternate),"Manipulation of model responses can result in widespread misinformation.",Configuration Error,High,9.5,"GPT-3, GPT-4, PaLM, LLaMA","May cause intentional misinformation and unauthorized actions.","Instances where model outputs were altered for malicious purposes.","Implement output validation, including human review before public release.","Output sanitization libraries and manual review processes","MITRE ATT&CK for AI","Cloud, On-premise",High,High,High,"May breach consumer protection laws","Ethical risk due to deliberate misinformation"
67,Hidden Feedback Channels (Second Instance),"Covert channels within feedback mechanisms can be exploited to modify outputs.",Adversarial Attack,Medium,6.0,"GPT-3, GPT-4, PaLM, LLaMA","May allow subtle manipulation of model behavior over time.","Exploitation of unmonitored feedback loops.","Monitor feedback inputs and restrict access to feedback channels.","Feedback monitoring and SIEM tools","NIST AI RMF","Cloud, On-premise",Medium,Medium,Medium,"Could conflict with internal governance policies","Ethically concerning if used to manipulate outcomes"
68,Input Inference Attacks (Variant),"Techniques to infer model input details from its outputs can compromise privacy.",API Security,Critical,7.8,"GPT-3, GPT-4, PaLM, LLaMA","May expose sensitive training or input data.","Advanced inference attacks demonstrated in adversarial research.","Use differential privacy and reduce output granularity.","Privacy-preserving ML tools like TensorFlow Privacy","ISO/IEC 27001","Cloud, Hybrid",High,High,High,"May violate data privacy standards","Significant ethical concerns"
69,Hidden Feedback Channels (Revisited),"Repeated exploitation of hidden feedback to subtly alter model behavior.",Configuration Error,High,7.9,"GPT-3, GPT-4, PaLM, LLaMA","May lead to unauthorized modifications and biased outputs.","Multiple instances of hidden channel exploitation.","Enforce strict controls and auditing on all feedback loops.","Feedback auditing tools and secure logging systems","NIST AI RMF","Cloud, On-premise",High,Medium,Medium,"May breach compliance guidelines","Ethically concerning due to covert alterations"
70,Invisible Prompt Attack (Revisited),"Embedding hidden instructions within prompts that bypass normal filters.",Access Control,Low,6.0,"GPT-3, GPT-4, PaLM, LLaMA","May lead to unauthorized control over model behavior.","Demonstrated in controlled adversarial experiments.","Implement robust input filtering and hidden instruction detection.","Input validation libraries and custom filters","MITRE ATT&CK for AI","Cloud, On-premise",Medium,Medium,Medium,"May violate secure coding standards","Risk of unethical model manipulation"
71,Undetected Model Modification (Alternate),"Subtle modifications that evade detection, altering model outputs.",Privacy Violation,High,5.6,"GPT-3, GPT-4, PaLM, LLaMA","May cause persistent output inaccuracies and data leakage.","Subtle changes in a model leading to wrong outputs in sensitive domains.","Use cryptographic hash checks and secure version control systems.","Version control and checksum verification tools","OWASP LLM AI Security Guide","Cloud, On-premise",High,Medium,Medium,"May breach internal audit requirements","Potential for significant ethical concerns"
72,Context Injection Attacks (Second Instance),"Injection of malicious context into ongoing sessions to manipulate outcomes.",Privacy Violation,Medium,6.4,"GPT-3, GPT-4, PaLM, LLaMA","May alter conversation flow and expose sensitive context.","Attacks that inject adversarial context into multi-turn conversations.","Sanitize and restrict session context; use strict validation.","Context validation libraries and AI safety guidelines","ISO/IEC 27001","Cloud, On-premise",Medium,Medium,Medium,"Could violate data integrity policies","Ethically concerning due to manipulation of conversation"
73,Overshadowing Vulnerability,"Overlapping input sequences can confuse the model and produce unpredictable outputs.",Data Leakage,Medium,4.7,"GPT-3, GPT-4, PaLM, LLaMA","May lead to unpredictable or incorrect responses.","Instances where similar inputs led to conflicting outputs.","Implement input disambiguation techniques and enforce strict parsing rules.","Robust parsing algorithms and input validation libraries","ISO/IEC 27001","Cloud, Hybrid",Medium,Medium,Medium,"May breach quality standards","Risk of misleading outputs"
74,Privacy Policy Violation,"Non-adherence to established privacy policies can result in legal and ethical breaches.",Model Manipulation,Critical,6.4,"GPT-3, GPT-4, PaLM, LLaMA","May expose personal data and result in legal action.","Violations similar to regulatory actions against major tech firms.","Regularly review and update privacy policies; train staff on compliance.","Privacy compliance tools and legal consulting services","NIST AI RMF","Cloud, On-premise",High,Low,Medium,"Violates GDPR, CCPA and other privacy laws","Severe ethical implications"
75,Exposed Data During Debugging,"Debug logs or error messages leaking sensitive information during development.",Model Manipulation,Medium,4.7,"GPT-3, GPT-4, PaLM, LLaMA","May expose confidential internal data.","Incidents where debug logs revealed sensitive system details.","Disable debug logs in production and sanitize error messages.","Secure logging frameworks with production settings like Log4j","MITRE ATT&CK for AI","On-premise, Cloud",Medium,Low,Low,"May violate internal data protection policies","Risk of inadvertent data exposure"
76,Poisoned Model Updates,"Malicious updates introduced into the model update pipeline compromise behavior.",Output Manipulation,Low,8.6,"GPT-3, GPT-4, PaLM, LLaMA","May cause sudden and dangerous changes in model outputs.","Backdoored updates inserted into CI/CD pipelines.","Validate and test all model updates in isolated environments; secure update pipelines.","CI/CD tools with security scanning like Jenkins with plugins","MITRE ATT&CK for AI","Cloud, Hybrid",High,High,High,"May breach software update regulations","High risk of ethical and operational compromise"
77,Unrestricted LLM Functions (Expanded),"Broad access to non-critical functions increases potential for misuse.",Input Manipulation,Low,6.9,"GPT-3, GPT-4, PaLM, LLaMA","May allow attackers to manipulate model behavior.","Instances where excessive function access led to security issues.","Restrict functionality to essential operations and enforce sandboxing.","Secure sandbox environments like Docker containers","ISO/IEC 27001","Cloud, On-premise",Medium,Medium,Medium,"May violate internal security policies","Ethically concerning if misused"
78,Backdoor Attacks,"Insertion of covert backdoors into models allows future unauthorized access.",Model Manipulation,High,8.0,"GPT-3, GPT-4, PaLM, LLaMA","May enable persistent unauthorized control over the model.","Backdoors discovered in compromised proprietary models.","Perform rigorous security audits and use code analysis tools.","Static and dynamic code analysis tools; security audits","MITRE ATT&CK for AI","Cloud, On-premise",High,High,High,"May breach intellectual property and security regulations","High ethical and legal concerns"
79,Response Timing Analysis (Advanced),"Using advanced timing analysis to infer internal model secrets.",Data Leakage,Critical,9.7,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to extraction of encryption keys or internal logic.","Highly sophisticated timing attacks demonstrated in research.","Implement randomized delays and constant-time algorithms.","APM tools and cryptographic hardening libraries","ISO/IEC 27001","Cloud, On-premise",High,High,High,"May breach confidentiality standards","Severe privacy risks"
80,Predictable Inference Time,"Consistent inference times can be exploited to infer sensitive details.",Configuration Error,Medium,9.0,"GPT-3, GPT-4, PaLM, LLaMA","May allow attackers to deduce internal states from timing patterns.","Attacks similar to those on constant-time encryption routines.","Introduce random delays and implement constant-time processing techniques.","Code analysis tools and randomization libraries","MITRE ATT&CK for AI","Cloud, On-premise",Medium,Medium,Medium,"May conflict with performance guarantees","Risk of exposing internal processing details"
81,Oversharing of Data Insights,"Excessive detail in analytic outputs can expose underlying sensitive data.",Model Manipulation,Medium,9.5,"GPT-3, GPT-4, PaLM, LLaMA","May result in re-identification or leakage of confidential data.","Incidents where detailed analytics revealed user information.","Limit data granularity and enforce data aggregation and anonymization.","Data masking tools and secure reporting platforms","NIST AI RMF","Cloud, On-premise",Medium,Medium,Medium,"May breach privacy regulations","High ethical concerns regarding user privacy"
82,Cache Poisoning (Alternate),"Injecting malicious data into caches corrupts model outputs.",Data Leakage,Low,5.8,"GPT-3, GPT-4, PaLM, LLaMA","Leads to unreliable outputs and potential data corruption.","Examples include cache poisoning in DNS and web caches.","Validate cache integrity and implement secure cache eviction policies.","Secure caching solutions like Redis with enhanced security settings","MITRE ATT&CK for AI","Cloud, On-premise",Medium,Medium,Medium,"Could violate data integrity policies","Risk of misinformation"
83,Data Retention Issues (Alternate),"Retention of unnecessary data increases risk of breaches and misuse.",Adversarial Attack,Medium,4.2,"GPT-3, GPT-4, PaLM, LLaMA","May result in exposure of outdated but sensitive data.","Breaches occurring due to legacy data retention in outdated systems.","Automate data deletion processes and enforce strict retention policies.","Data management tools like Apache Atlas","ISO/IEC 27001","Cloud, Hybrid",Medium,Medium,Medium,"May violate GDPR and data minimization principles","Risk of privacy violations"
84,Model Drift (Alternate),"Gradual performance degradation due to evolving input distributions.",Configuration Error,Critical,5.8,"GPT-3, GPT-4, PaLM, LLaMA","Leads to increased errors and decreased reliability over time.","Models becoming less effective due to changing data patterns.","Continuously monitor model performance; schedule periodic retraining.","Model monitoring tools like Evidently AI","OWASP LLM AI Security Guide","Cloud, Hybrid",Medium,Low,Medium,"May breach quality assurance standards","Ethically concerning if decisions are based on outdated data"
85,Lack of Governance (Alternate),"Insufficient oversight leads to non-compliant and biased model deployment.",Configuration Error,Medium,7.0,"GPT-3, GPT-4, PaLM, LLaMA","May introduce biases and legal risks.","Instances of ungoverned AI deployments causing systemic bias.","Establish comprehensive AI governance and regular compliance audits.","AI governance platforms like IBM OpenPages","ISO/IEC 27001","Cloud, Hybrid",High,Medium,High,"Could violate multiple legal frameworks","High ethical risks"
86,Excessive Data Collection,"Collecting more data than necessary increases exposure to breaches.",Access Control,Low,6.6,"GPT-3, GPT-4, PaLM, LLaMA","May lead to privacy breaches and regulatory fines.","Instances where companies were fined for over-collection of user data.","Implement strict data minimization practices and transparent data collection policies.","Compliance management tools like TrustArc","MITRE ATT&CK for AI","Cloud, Hybrid",Medium,Low,Medium,"May breach GDPR/CCPA","Ethically concerning regarding user privacy"
87,Backend Server Exploitation (Alternate),"Exploiting vulnerabilities in backend servers supporting LLMs.",Input Manipulation,Low,9.2,"GPT-3, GPT-4, PaLM, LLaMA","Provides attackers a foothold into the overall system.","Exploitation of unpatched vulnerabilities in backend API servers.","Regularly patch and update servers; deploy IDS and firewalls.","Security tools like Snort IDS and OSSEC","NIST AI RMF","On-premise, Cloud",High,High,High,"May breach IT security standards","High risk to overall system integrity"
88,Overfitting Exploitation (Revisited),"Memorization of training data due to overfitting leads to sensitive data leaks.",API Security,Low,6.3,"GPT-3, GPT-4, PaLM, LLaMA","May reveal private training data under specific queries.","Extracting memorized sequences from overfitted models.","Use regularization and robust training practices; validate on diverse datasets.","ML libraries with regularization like scikit-learn","ISO/IEC 27001","Cloud, Hybrid",High,Medium,Medium,"May breach intellectual property rights","Risk of unintended data exposure"
89,Context Injection Attacks (Alternate 2),"Injecting false context into user interactions alters output integrity.",Input Manipulation,High,7.0,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to incorrect or malicious outputs in interactive systems.","Manipulation of chat context to alter responses in customer service bots.","Sanitize contextual data and restrict modifications in multi-turn sessions.","Context validation libraries","ISO/IEC 27001","Cloud, Web",Medium,Medium,Medium,"Could breach data integrity protocols","Ethically concerning due to misinformation"
90,Weak Protection for Sensitive Outputs (Revisited),"Inadequate output protection exposes confidential information.",Access Control,Critical,9.7,"GPT-3, GPT-4, PaLM, LLaMA","May cause exposure of sensitive information in generated outputs.","Incidents where sensitive data was inadvertently disclosed in reports.","Implement output filtering, redaction, and strict access controls.","Data masking and secure reporting systems","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"May violate privacy regulations","High risk to sensitive data"
91,Denial of Service,"Overloading model inputs to render the system unresponsive.",Model Exploitation,Medium,8.6,"GPT-3, GPT-4, PaLM, LLaMA","Can cause service outages and disrupt operations.","DDoS attacks against AI-powered services.","Implement network traffic monitoring, rate limiting, and DDoS protection.","Services like Cloudflare DDoS Protection or AWS Shield","MITRE ATT&CK for AI","Cloud, Hybrid",Medium,Low,Medium,"May breach SLA requirements","Operational disruption concerns"
92,Sensitive Data Exfiltration,"Unauthorized extraction of sensitive data through the model.",Configuration Error,Critical,5.7,"GPT-3, GPT-4, PaLM, LLaMA","Leads to loss of confidential data and intellectual property.","Exfiltration attacks targeting sensitive data in model outputs.","Monitor for anomalous data access; implement DLP measures.","Data Loss Prevention solutions like McAfee DLP","OWASP LLM AI Security Guide","Cloud, On-premise",High,Medium,Medium,"May breach data protection laws","High ethical and legal concerns"
93,Response Manipulation (Revisited),"Subtle manipulation of model outputs for malicious purposes.",Adversarial Attack,Low,8.9,"GPT-3, GPT-4, PaLM, LLaMA","May mislead users or cause operational errors.","Instances of manipulated outputs in public-facing systems.","Validate outputs and implement robust sanitization and review processes.","Output validation libraries and manual oversight","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"Could violate consumer protection laws","Ethically concerning if used to deceive"
94,Invisible Prompt Attack (Revisited),"Embedding hidden instructions within prompts to alter model behavior.",Model Manipulation,Medium,8.6,"GPT-3, GPT-4, PaLM, LLaMA","May lead to unintended manipulation of model outputs.","Demonstrated in adversarial testing of prompt filters.","Implement detection mechanisms for hidden content and enhance input filtering.","Input validation libraries and custom content filters","NIST AI RMF","Cloud, On-premise",High,Medium,Medium,"May breach internal security policies","Ethically concerning due to covert manipulation"
95,Cross-Tenant Attacks,"In multi-tenant environments, one tenant may access anotherâ€™s data.",Data Leakage,Low,6.3,"GPT-3, GPT-4, PaLM, LLaMA","Risks data leakage and unauthorized access between tenants.","Multi-tenant data breaches due to inadequate isolation.","Enforce tenant isolation policies and use tenant-aware access controls.","Multi-tenancy frameworks and IAM solutions","MITRE ATT&CK for AI","Cloud",Medium,Medium,Medium,"May violate data segregation standards","High risk to customer data"
96,Weak Model Parameter Encryption (Revisited),"Unencrypted model parameters allow attackers to steal proprietary information.",Data Leakage,Critical,6.5,"GPT-3, GPT-4, PaLM, LLaMA","May result in intellectual property theft and misuse.","Incidents of unencrypted model parameters being extracted.","Encrypt model parameters; employ secure key management protocols.","Encryption libraries like OpenSSL or AWS KMS","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"May breach data security regulations","High risk to proprietary assets"
97,External System Integration Risks (Alternate),"Compromised third-party integrations can introduce vulnerabilities.",Data Leakage,Critical,5.0,"GPT-3, GPT-4, PaLM, LLaMA","May provide attackers with indirect access to models.","Exploitation of vulnerable third-party integrations in supply chains.","Vet third-party components rigorously and monitor external interactions.","SIEM systems and integration monitoring tools","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,High,"May breach third-party compliance requirements","High risk to overall system trust"
98,Incorrect Model Configuration (Revisited),"Misconfigured models can expose debug information and insecure settings.",Privacy Violation,Medium,4.6,"GPT-3, GPT-4, PaLM, LLaMA","May leak internal configuration details.","Models deployed with debug mode enabled in production.","Follow secure configuration management best practices; disable debug modes.","Configuration management tools like Ansible","NIST ATT&CK for AI","Cloud, On-premise",Medium,Low,Low,"May violate internal policies","Risk of inadvertent exposure"
99,Improper Input Filtering (Revisited),"Failure to properly filter inputs may lead to code injection attacks.",Model Exploitation,Critical,9.4,"GPT-3, GPT-4, PaLM, LLaMA","Leads to severe injection vulnerabilities.","Examples of injection attacks due to unfiltered user inputs.","Implement robust input filtering using allowlists and sanitization.","Security libraries like OWASP ESAPI","NIST ATT&CK for AI","Web, Cloud",High,High,High,"May violate security standards","High ethical and operational risk"
100,Insufficient Encryption,"Use of weak encryption algorithms makes data susceptible to interception.",Configuration Error,High,9.3,"GPT-3, GPT-4, PaLM, LLaMA","Increases risk of data breaches and interception.","Historical breaches due to weak encryption protocols.","Adopt strong encryption algorithms; regularly update encryption standards.","Encryption libraries like OpenSSL with strong cipher suites","NIST ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"May breach data security regulations","High risk to confidential data"
101,Adversarial Reverse Engineering,"Systematic probing of a model to deduce its internal structure and training data.",Reverse Engineering,Critical,9.2,"GPT-3, GPT-4, PaLM, LLaMA","Risk of intellectual property theft and sensitive data exposure.","Researchers mapping model behavior through crafted queries.","Implement query rate limiting, monitor abnormal patterns, and apply output obfuscation.","Advanced monitoring solutions and differential privacy tools","NIST AI RMF","Cloud, Hybrid",High,High,High,"May breach IP protection standards","Ethically concerning due to secret extraction"
102,Biased Output Propagation (Alternate),"Unintended reinforcement of stereotypes in model outputs causing unfair decisions.",Ethical & Social,High,8.0,"GPT-3, GPT-4, PaLM, LLaMA","Damages reputation and may lead to legal actions.","Biased outputs affecting hiring or lending decisions in real scenarios.","Deploy bias detection systems and continuously audit outputs with diverse datasets.","Bias mitigation toolkits like IBM AI Fairness 360 or Fairlearn","OWASP LLM AI Security Guide","Cloud, On-premise, Web",Medium,Low,Medium,"May violate anti-discrimination laws","High ethical and social concerns"
103,Data Poisoning During Training (Alternate),"Introduction of malicious training data that skews model behavior.",Input Manipulation,Critical,9.0,"GPT-3, GPT-4, PaLM, LLaMA","Can systematically alter outputs to favor attackers.","Adversaries injecting manipulated data into training pipelines.","Employ strict data validation, track data provenance, and use robust training protocols.","Data validation tools and secure training pipelines","MITRE ATT&CK for AI","Cloud, Hybrid",High,High,High,"May breach data integrity regulations","High risk of systematic harm"
104,Interactive Feedback Exploitation (Alternate),"Abuse of interactive learning loops to gradually shift model behavior.",Adversarial Attack,High,8.4,"GPT-3, GPT-4, PaLM, LLaMA","Leads to covert model degradation over time.","Exploitation of feedback in recommendation or chat systems.","Implement safeguards in feedback channels, enforce rate limits, and conduct periodic reviews.","Feedback monitoring tools and anomaly detection systems","NIST AI RMF","Cloud, Hybrid",High,Medium,Medium,"May conflict with quality control regulations","Ethically concerning due to gradual manipulation"
105,Context Leakage via Multi-Turn Interactions (Extended),"Cumulative context in long conversations reveals sensitive historical data.",Data Leakage,High,8.7,"GPT-3, GPT-4, PaLM, LLaMA","Exposes personal and sensitive data from previous interactions.","Multi-turn chat sessions inadvertently disclosing confidential context.","Limit context retention; segment sessions and apply anonymization.","Session management systems and context-aware filters","OWASP LLM AI Security Guide","Cloud, Hybrid",High,Medium,High,"May violate data protection laws","High risk to personal privacy"
106,Supply Chain Compromise,"Compromise of external libraries or components can infiltrate the LLM environment.",Supply Chain,Critical,9.0,"GPT-3, GPT-4, PaLM, LLaMA","May introduce hidden vulnerabilities or malicious code.","Incidents where third-party libraries were compromised and exploited.","Conduct rigorous security reviews of third-party components; use integrity verification.","Code analysis tools and secure repository management","MITRE ATT&CK for AI","Cloud, On-premise",High,High,High,"May breach supply chain security standards","High risk to overall system integrity"
107,Social Engineering Assisted Exploitation,"Attackers use social engineering to gain access or influence model outputs.",Human Factor,High,7.5,"GPT-3, GPT-4, PaLM, LLaMA","Leads to unauthorized access or manipulated data inputs.","Phishing attacks that trick users into providing access credentials.","Implement strong user training and multi-factor authentication.","Security awareness programs and MFA solutions","OWASP LLM AI Security Guide","Cloud, Web",Medium,Medium,Medium,"May breach organizational security policies","Ethically concerning due to manipulation"
108,Adversarial Example Crafting,"Crafting inputs specifically to mislead the model into wrong predictions.",Adversarial Attack,High,8.8,"GPT-3, GPT-4, PaLM, LLaMA","Can result in systematically biased or incorrect outputs.","Adversarial examples used in image and text classification failures.","Integrate adversarial training and continuously update models against new attack vectors.","Adversarial training frameworks like CleverHans","MITRE ATT&CK for AI","Cloud, Hybrid",High,High,High,"May breach performance standards","High risk of manipulated outcomes"
109,Insecure Data Transmission,"Lack of encryption in data transmission exposes information to interception.",Configuration Error,High,8.0,"GPT-3, GPT-4, PaLM, LLaMA","Exposes sensitive data during transit.","Eavesdropping attacks on unencrypted API communications.","Enforce TLS/SSL encryption for all data in transit.","TLS/SSL certificate management tools","ISO/IEC 27001","Cloud, On-premise",Medium,Low,Medium,"May violate data protection regulations","High risk to confidential data"
110,Weak Cryptographic Protocols,"Use of outdated cryptographic protocols exposes data to decryption attacks.",Configuration Error,High,8.5,"GPT-3, GPT-4, PaLM, LLaMA","Risks exposure of confidential communications and stored data.","Historical breaches due to deprecated encryption standards.","Upgrade to modern, secure cryptographic protocols and ciphers.","Modern encryption libraries like OpenSSL with updated ciphers","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"May breach regulatory standards","High risk to data security"
111,Insider Threat Exploitation,"Malicious insiders leveraging legitimate access to compromise model integrity.",Access Control,Critical,8.0,"GPT-3, GPT-4, PaLM, LLaMA","Can lead to significant internal data breaches and manipulation.","Insider cases where privileged access was abused for data theft.","Implement strict access controls, regular audits, and behavior monitoring.","IAM solutions and user behavior analytics","OWASP LLM AI Security Guide","Cloud, On-premise",High,Medium,High,"May violate internal compliance and privacy policies","High ethical and legal concerns"
112,Inadequate Audit Trails,"Insufficient logging and auditing hinder forensic analysis after incidents.",Data Leakage,Medium,7.0,"GPT-3, GPT-4, PaLM, LLaMA","May impede incident response and breach investigations.","Lack of audit logs during a significant data breach incident.","Implement comprehensive logging, audit trails, and regular log reviews.","Centralized logging platforms like Splunk or ELK Stack","ISO/IEC 27001","Cloud, On-premise",Medium,Low,Medium,"May breach compliance requirements","Risk of delayed detection and response"
113,Exposed Debug Interfaces,"Debug interfaces left accessible in production can be exploited by attackers.",Configuration Error,High,7.2,"GPT-3, GPT-4, PaLM, LLaMA","May reveal internal system details and allow unauthorized access.","Accidental exposure of debug ports in cloud deployments.","Disable or restrict access to debug interfaces in production environments.","Network access controls and firewall rules","OWASP LLM AI Security Guide","Cloud, On-premise",High,Medium,Medium,"May breach operational security standards","Risk of internal data exposure"
114,Data Aggregation Vulnerability,"Aggregation of non-sensitive data inadvertently reveals sensitive patterns.",Data Leakage,Medium,7.0,"GPT-3, GPT-4, PaLM, LLaMA","May lead to re-identification of individuals from aggregated data.","Cases where anonymized datasets were re-identified through aggregation.","Apply strict thresholding and anonymization to aggregated datasets.","Data masking and aggregation tools","ISO/IEC 27001","Cloud, Hybrid",Medium,Medium,Medium,"May violate privacy regulations","Ethically concerning due to potential re-identification"
115,Algorithmic Bias Amplification,"Feedback loops amplify existing biases in data, leading to unfair outputs.",Ethical & Social,High,8.2,"GPT-3, GPT-4, PaLM, LLaMA","May reinforce societal biases and discriminatory practices.","Incidents where biased models affected hiring decisions.","Implement bias audits and diversify training data; adjust algorithmic parameters.","Bias detection tools and fairness frameworks like Fairlearn","OWASP LLM AI Security Guide","Cloud, On-premise, Web",High,Medium,Medium,"May violate anti-discrimination laws","High ethical and social concerns"
116,Quantum Vulnerability Preparedness,"Future threats from quantum computing could break current encryption.",Configuration Error,High,9.0,"GPT-3, GPT-4, PaLM, LLaMA","Risk of future decryption of sensitive data when quantum computers mature.","Theoretical vulnerabilities in current cryptographic schemes.","Research and plan migration to quantum-resistant algorithms.","Emerging quantum-safe encryption libraries","MITRE ATT&CK for AI","Cloud, On-premise",High,High,High,"Currently not applicable but critical for future-proofing","Ethically important for long-term data security"
117,Federated Learning Poisoning,"Manipulating updates in federated learning to inject malicious behavior.",Input Manipulation,Critical,8.5,"GPT-3, GPT-4, PaLM, LLaMA","May compromise distributed model training and integrity.","Attacks on federated learning systems in mobile applications.","Implement secure aggregation protocols and robust anomaly detection.","Federated learning security frameworks and anomaly detectors","MITRE ATT&CK for AI","Cloud, Hybrid",High,High,High,"May breach data integrity and trust standards","High risk to collaborative AI systems"
118,Malicious Hyperparameter Tuning,"Attackers manipulating hyperparameters to degrade model performance.",Configuration Error,High,8.0,"GPT-3, GPT-4, PaLM, LLaMA","Can cause suboptimal model performance and increased error rates.","Incidents where tuning led to degraded model accuracy.","Establish secure, automated hyperparameter tuning with strict monitoring.","Automated ML tools with built-in security measures","OWASP LLM AI Security Guide","Cloud, Hybrid",Medium,Medium,Medium,"May affect product performance guarantees","Risk of unethical degradation"
119,Insecure Model Deployment,"Improper deployment practices lead to exposure of sensitive model artifacts.",Configuration Error,Critical,8.3,"GPT-3, GPT-4, PaLM, LLaMA","May expose proprietary model details and enable tampering.","Deployment of models with exposed administrative interfaces.","Adopt secure deployment practices and isolate model environments.","Deployment orchestration tools with security features like Kubernetes","MITRE ATT&CK for AI","Cloud, On-premise",High,Medium,Medium,"May breach intellectual property policies","High risk of proprietary data exposure"
120,Ethical Data Sourcing Violation,"Sourcing training data unethically can lead to legal and moral issues.",Ethical & Social,High,8.7,"GPT-3, GPT-4, PaLM, LLaMA","May result in models built on biased or illegally obtained data.","Incidents involving unauthorized data scraping and usage.","Implement strict data sourcing audits and ethical data collection policies.","Data provenance tools and compliance auditing platforms","OWASP LLM AI Security Guide","Cloud, Hybrid",High,Medium,Medium,"May violate copyright and data protection laws","Severe ethical and legal implications"
